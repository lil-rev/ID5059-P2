{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8612598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.24.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: imblearn in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imblearn) (0.10.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ffinl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy pandas matplotlib scikit-learn seaborn imblearn \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "\n",
    "# import SMOTE and RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# logisitc regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#set seed\n",
    "\n",
    "SEED = 618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad88b768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.074329</td>\n",
       "      <td>-0.129425</td>\n",
       "      <td>-1.137418</td>\n",
       "      <td>0.412846</td>\n",
       "      <td>-0.192638</td>\n",
       "      <td>-1.210144</td>\n",
       "      <td>0.110697</td>\n",
       "      <td>-0.263477</td>\n",
       "      <td>0.742144</td>\n",
       "      <td>0.108782</td>\n",
       "      <td>-1.070243</td>\n",
       "      <td>-0.234910</td>\n",
       "      <td>-1.099360</td>\n",
       "      <td>0.502467</td>\n",
       "      <td>0.169318</td>\n",
       "      <td>0.065688</td>\n",
       "      <td>-0.306957</td>\n",
       "      <td>-0.323800</td>\n",
       "      <td>0.103348</td>\n",
       "      <td>-0.292969</td>\n",
       "      <td>-0.334701</td>\n",
       "      <td>-0.887840</td>\n",
       "      <td>0.336701</td>\n",
       "      <td>-0.110835</td>\n",
       "      <td>-0.291459</td>\n",
       "      <td>0.207733</td>\n",
       "      <td>-0.076576</td>\n",
       "      <td>-0.059577</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.998827</td>\n",
       "      <td>-1.250891</td>\n",
       "      <td>-0.520969</td>\n",
       "      <td>-0.894539</td>\n",
       "      <td>-1.122528</td>\n",
       "      <td>-0.270866</td>\n",
       "      <td>-1.029289</td>\n",
       "      <td>0.050198</td>\n",
       "      <td>-0.109948</td>\n",
       "      <td>0.908773</td>\n",
       "      <td>0.836798</td>\n",
       "      <td>-0.056580</td>\n",
       "      <td>-0.120990</td>\n",
       "      <td>-0.144028</td>\n",
       "      <td>-0.039582</td>\n",
       "      <td>1.653057</td>\n",
       "      <td>-0.253599</td>\n",
       "      <td>-0.814354</td>\n",
       "      <td>0.716784</td>\n",
       "      <td>0.065717</td>\n",
       "      <td>0.054848</td>\n",
       "      <td>-0.038367</td>\n",
       "      <td>0.133518</td>\n",
       "      <td>-0.461928</td>\n",
       "      <td>-0.465491</td>\n",
       "      <td>-0.464655</td>\n",
       "      <td>-0.009413</td>\n",
       "      <td>-0.038238</td>\n",
       "      <td>84.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091535</td>\n",
       "      <td>1.004517</td>\n",
       "      <td>-0.223445</td>\n",
       "      <td>-0.435249</td>\n",
       "      <td>0.667548</td>\n",
       "      <td>-0.988351</td>\n",
       "      <td>0.948146</td>\n",
       "      <td>-0.084789</td>\n",
       "      <td>-0.042027</td>\n",
       "      <td>-0.818383</td>\n",
       "      <td>-0.376512</td>\n",
       "      <td>-0.226546</td>\n",
       "      <td>-0.552869</td>\n",
       "      <td>-0.886466</td>\n",
       "      <td>-0.180890</td>\n",
       "      <td>0.230286</td>\n",
       "      <td>0.590579</td>\n",
       "      <td>-0.321590</td>\n",
       "      <td>-0.433959</td>\n",
       "      <td>-0.021375</td>\n",
       "      <td>-0.326725</td>\n",
       "      <td>-0.803736</td>\n",
       "      <td>0.154495</td>\n",
       "      <td>0.951233</td>\n",
       "      <td>-0.506919</td>\n",
       "      <td>0.085046</td>\n",
       "      <td>0.224458</td>\n",
       "      <td>0.087356</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.979649</td>\n",
       "      <td>-0.184949</td>\n",
       "      <td>-1.064206</td>\n",
       "      <td>0.120125</td>\n",
       "      <td>-0.215238</td>\n",
       "      <td>-0.648829</td>\n",
       "      <td>-0.087826</td>\n",
       "      <td>-0.035367</td>\n",
       "      <td>0.885838</td>\n",
       "      <td>-0.007527</td>\n",
       "      <td>0.637441</td>\n",
       "      <td>0.676960</td>\n",
       "      <td>-1.504823</td>\n",
       "      <td>0.554039</td>\n",
       "      <td>-0.824356</td>\n",
       "      <td>-0.527267</td>\n",
       "      <td>-0.095838</td>\n",
       "      <td>-0.312519</td>\n",
       "      <td>0.642659</td>\n",
       "      <td>-0.340089</td>\n",
       "      <td>-0.095514</td>\n",
       "      <td>-0.079792</td>\n",
       "      <td>0.167701</td>\n",
       "      <td>-0.042939</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>-0.096148</td>\n",
       "      <td>-0.057780</td>\n",
       "      <td>-0.073839</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.025898</td>\n",
       "      <td>-0.171827</td>\n",
       "      <td>1.203717</td>\n",
       "      <td>1.243900</td>\n",
       "      <td>-0.636572</td>\n",
       "      <td>1.099074</td>\n",
       "      <td>-0.938651</td>\n",
       "      <td>0.569239</td>\n",
       "      <td>0.692665</td>\n",
       "      <td>-0.097495</td>\n",
       "      <td>1.338869</td>\n",
       "      <td>1.391399</td>\n",
       "      <td>-0.128167</td>\n",
       "      <td>-0.081836</td>\n",
       "      <td>0.100548</td>\n",
       "      <td>-0.338937</td>\n",
       "      <td>0.090864</td>\n",
       "      <td>-0.423645</td>\n",
       "      <td>-0.731939</td>\n",
       "      <td>-0.203628</td>\n",
       "      <td>0.099157</td>\n",
       "      <td>0.608908</td>\n",
       "      <td>0.027901</td>\n",
       "      <td>-0.262813</td>\n",
       "      <td>0.257834</td>\n",
       "      <td>-0.252829</td>\n",
       "      <td>0.108338</td>\n",
       "      <td>0.021051</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219124</th>\n",
       "      <td>219124</td>\n",
       "      <td>120580.0</td>\n",
       "      <td>1.891079</td>\n",
       "      <td>-1.272908</td>\n",
       "      <td>-3.783908</td>\n",
       "      <td>-1.388939</td>\n",
       "      <td>2.012789</td>\n",
       "      <td>2.666080</td>\n",
       "      <td>0.151740</td>\n",
       "      <td>0.401934</td>\n",
       "      <td>-1.102824</td>\n",
       "      <td>0.858158</td>\n",
       "      <td>-0.280639</td>\n",
       "      <td>0.007976</td>\n",
       "      <td>-0.124950</td>\n",
       "      <td>0.914374</td>\n",
       "      <td>-0.073169</td>\n",
       "      <td>-2.309929</td>\n",
       "      <td>-0.041423</td>\n",
       "      <td>1.190526</td>\n",
       "      <td>-0.281848</td>\n",
       "      <td>-0.195703</td>\n",
       "      <td>-0.181369</td>\n",
       "      <td>-0.456538</td>\n",
       "      <td>-0.069571</td>\n",
       "      <td>0.756765</td>\n",
       "      <td>0.244479</td>\n",
       "      <td>-0.147566</td>\n",
       "      <td>-0.054725</td>\n",
       "      <td>-0.044588</td>\n",
       "      <td>198.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219125</th>\n",
       "      <td>219125</td>\n",
       "      <td>120580.0</td>\n",
       "      <td>0.139724</td>\n",
       "      <td>0.948649</td>\n",
       "      <td>-2.913655</td>\n",
       "      <td>-2.184829</td>\n",
       "      <td>1.883716</td>\n",
       "      <td>-1.056824</td>\n",
       "      <td>1.725624</td>\n",
       "      <td>0.018089</td>\n",
       "      <td>-0.823494</td>\n",
       "      <td>-0.257933</td>\n",
       "      <td>-0.457534</td>\n",
       "      <td>0.516146</td>\n",
       "      <td>-0.071240</td>\n",
       "      <td>1.310799</td>\n",
       "      <td>-1.892909</td>\n",
       "      <td>-0.318780</td>\n",
       "      <td>-0.917395</td>\n",
       "      <td>0.098397</td>\n",
       "      <td>-0.195558</td>\n",
       "      <td>-0.116538</td>\n",
       "      <td>0.491469</td>\n",
       "      <td>1.478823</td>\n",
       "      <td>-0.085398</td>\n",
       "      <td>-0.091409</td>\n",
       "      <td>-1.053488</td>\n",
       "      <td>0.467570</td>\n",
       "      <td>0.358918</td>\n",
       "      <td>0.294735</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219126</th>\n",
       "      <td>219126</td>\n",
       "      <td>120580.0</td>\n",
       "      <td>2.058343</td>\n",
       "      <td>-0.038993</td>\n",
       "      <td>-1.928553</td>\n",
       "      <td>0.330117</td>\n",
       "      <td>0.270127</td>\n",
       "      <td>-0.735664</td>\n",
       "      <td>-0.173878</td>\n",
       "      <td>0.144823</td>\n",
       "      <td>0.849289</td>\n",
       "      <td>-0.136498</td>\n",
       "      <td>0.179926</td>\n",
       "      <td>-1.769641</td>\n",
       "      <td>-3.937694</td>\n",
       "      <td>0.031346</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.883566</td>\n",
       "      <td>0.391801</td>\n",
       "      <td>1.007789</td>\n",
       "      <td>0.303376</td>\n",
       "      <td>-0.384830</td>\n",
       "      <td>-0.306640</td>\n",
       "      <td>-0.965783</td>\n",
       "      <td>0.307799</td>\n",
       "      <td>-0.021434</td>\n",
       "      <td>-0.343989</td>\n",
       "      <td>0.181065</td>\n",
       "      <td>-0.098387</td>\n",
       "      <td>-0.044064</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219127</th>\n",
       "      <td>219127</td>\n",
       "      <td>120580.0</td>\n",
       "      <td>2.079227</td>\n",
       "      <td>-2.162389</td>\n",
       "      <td>-1.785833</td>\n",
       "      <td>-2.804889</td>\n",
       "      <td>0.552845</td>\n",
       "      <td>4.038013</td>\n",
       "      <td>-2.155900</td>\n",
       "      <td>1.023785</td>\n",
       "      <td>-0.865242</td>\n",
       "      <td>1.536193</td>\n",
       "      <td>-0.058879</td>\n",
       "      <td>-0.885949</td>\n",
       "      <td>-0.254718</td>\n",
       "      <td>-0.425730</td>\n",
       "      <td>0.665556</td>\n",
       "      <td>-0.336634</td>\n",
       "      <td>0.301966</td>\n",
       "      <td>0.391249</td>\n",
       "      <td>0.037770</td>\n",
       "      <td>-0.190984</td>\n",
       "      <td>0.109909</td>\n",
       "      <td>0.590401</td>\n",
       "      <td>0.286621</td>\n",
       "      <td>0.675660</td>\n",
       "      <td>-0.510736</td>\n",
       "      <td>-0.090044</td>\n",
       "      <td>0.056749</td>\n",
       "      <td>-0.017126</td>\n",
       "      <td>88.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219128</th>\n",
       "      <td>219128</td>\n",
       "      <td>120580.0</td>\n",
       "      <td>-0.431758</td>\n",
       "      <td>1.299171</td>\n",
       "      <td>-0.571602</td>\n",
       "      <td>-1.161499</td>\n",
       "      <td>1.141765</td>\n",
       "      <td>-1.258871</td>\n",
       "      <td>1.701553</td>\n",
       "      <td>-0.454580</td>\n",
       "      <td>-0.556978</td>\n",
       "      <td>-0.049454</td>\n",
       "      <td>1.374548</td>\n",
       "      <td>1.172926</td>\n",
       "      <td>0.722704</td>\n",
       "      <td>0.525669</td>\n",
       "      <td>-0.926260</td>\n",
       "      <td>-0.379812</td>\n",
       "      <td>-0.640176</td>\n",
       "      <td>-0.161739</td>\n",
       "      <td>0.034470</td>\n",
       "      <td>0.058133</td>\n",
       "      <td>0.225629</td>\n",
       "      <td>0.988442</td>\n",
       "      <td>-0.224609</td>\n",
       "      <td>0.082977</td>\n",
       "      <td>-0.335529</td>\n",
       "      <td>0.042237</td>\n",
       "      <td>0.304965</td>\n",
       "      <td>0.240049</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219129 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      Time        V1        V2        V3        V4        V5   \n",
       "0            0       0.0  2.074329 -0.129425 -1.137418  0.412846 -0.192638  \\\n",
       "1            1       0.0  1.998827 -1.250891 -0.520969 -0.894539 -1.122528   \n",
       "2            2       0.0  0.091535  1.004517 -0.223445 -0.435249  0.667548   \n",
       "3            3       0.0  1.979649 -0.184949 -1.064206  0.120125 -0.215238   \n",
       "4            4       0.0  1.025898 -0.171827  1.203717  1.243900 -0.636572   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "219124  219124  120580.0  1.891079 -1.272908 -3.783908 -1.388939  2.012789   \n",
       "219125  219125  120580.0  0.139724  0.948649 -2.913655 -2.184829  1.883716   \n",
       "219126  219126  120580.0  2.058343 -0.038993 -1.928553  0.330117  0.270127   \n",
       "219127  219127  120580.0  2.079227 -2.162389 -1.785833 -2.804889  0.552845   \n",
       "219128  219128  120580.0 -0.431758  1.299171 -0.571602 -1.161499  1.141765   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12   \n",
       "0      -1.210144  0.110697 -0.263477  0.742144  0.108782 -1.070243 -0.234910  \\\n",
       "1      -0.270866 -1.029289  0.050198 -0.109948  0.908773  0.836798 -0.056580   \n",
       "2      -0.988351  0.948146 -0.084789 -0.042027 -0.818383 -0.376512 -0.226546   \n",
       "3      -0.648829 -0.087826 -0.035367  0.885838 -0.007527  0.637441  0.676960   \n",
       "4       1.099074 -0.938651  0.569239  0.692665 -0.097495  1.338869  1.391399   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "219124  2.666080  0.151740  0.401934 -1.102824  0.858158 -0.280639  0.007976   \n",
       "219125 -1.056824  1.725624  0.018089 -0.823494 -0.257933 -0.457534  0.516146   \n",
       "219126 -0.735664 -0.173878  0.144823  0.849289 -0.136498  0.179926 -1.769641   \n",
       "219127  4.038013 -2.155900  1.023785 -0.865242  1.536193 -0.058879 -0.885949   \n",
       "219128 -1.258871  1.701553 -0.454580 -0.556978 -0.049454  1.374548  1.172926   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19   \n",
       "0      -1.099360  0.502467  0.169318  0.065688 -0.306957 -0.323800  0.103348  \\\n",
       "1      -0.120990 -0.144028 -0.039582  1.653057 -0.253599 -0.814354  0.716784   \n",
       "2      -0.552869 -0.886466 -0.180890  0.230286  0.590579 -0.321590 -0.433959   \n",
       "3      -1.504823  0.554039 -0.824356 -0.527267 -0.095838 -0.312519  0.642659   \n",
       "4      -0.128167 -0.081836  0.100548 -0.338937  0.090864 -0.423645 -0.731939   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "219124 -0.124950  0.914374 -0.073169 -2.309929 -0.041423  1.190526 -0.281848   \n",
       "219125 -0.071240  1.310799 -1.892909 -0.318780 -0.917395  0.098397 -0.195558   \n",
       "219126 -3.937694  0.031346  0.028100  0.883566  0.391801  1.007789  0.303376   \n",
       "219127 -0.254718 -0.425730  0.665556 -0.336634  0.301966  0.391249  0.037770   \n",
       "219128  0.722704  0.525669 -0.926260 -0.379812 -0.640176 -0.161739  0.034470   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26   \n",
       "0      -0.292969 -0.334701 -0.887840  0.336701 -0.110835 -0.291459  0.207733  \\\n",
       "1       0.065717  0.054848 -0.038367  0.133518 -0.461928 -0.465491 -0.464655   \n",
       "2      -0.021375 -0.326725 -0.803736  0.154495  0.951233 -0.506919  0.085046   \n",
       "3      -0.340089 -0.095514 -0.079792  0.167701 -0.042939  0.000799 -0.096148   \n",
       "4      -0.203628  0.099157  0.608908  0.027901 -0.262813  0.257834 -0.252829   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "219124 -0.195703 -0.181369 -0.456538 -0.069571  0.756765  0.244479 -0.147566   \n",
       "219125 -0.116538  0.491469  1.478823 -0.085398 -0.091409 -1.053488  0.467570   \n",
       "219126 -0.384830 -0.306640 -0.965783  0.307799 -0.021434 -0.343989  0.181065   \n",
       "219127 -0.190984  0.109909  0.590401  0.286621  0.675660 -0.510736 -0.090044   \n",
       "219128  0.058133  0.225629  0.988442 -0.224609  0.082977 -0.335529  0.042237   \n",
       "\n",
       "             V27       V28  Amount  Class  \n",
       "0      -0.076576 -0.059577    1.98      0  \n",
       "1      -0.009413 -0.038238   84.00      0  \n",
       "2       0.224458  0.087356    2.69      0  \n",
       "3      -0.057780 -0.073839    1.00      0  \n",
       "4       0.108338  0.021051    1.00      0  \n",
       "...          ...       ...     ...    ...  \n",
       "219124 -0.054725 -0.044588  198.65      0  \n",
       "219125  0.358918  0.294735   24.00      0  \n",
       "219126 -0.098387 -0.044064    1.79      0  \n",
       "219127  0.056749 -0.017126   88.00      0  \n",
       "219128  0.304965  0.240049    3.78      0  \n",
       "\n",
       "[219129 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219129</td>\n",
       "      <td>120580.0</td>\n",
       "      <td>2.115519</td>\n",
       "      <td>-0.691809</td>\n",
       "      <td>-1.305514</td>\n",
       "      <td>-0.685655</td>\n",
       "      <td>-0.641265</td>\n",
       "      <td>-0.764784</td>\n",
       "      <td>-0.924262</td>\n",
       "      <td>-0.023030</td>\n",
       "      <td>-0.230126</td>\n",
       "      <td>0.220610</td>\n",
       "      <td>1.058325</td>\n",
       "      <td>-0.723363</td>\n",
       "      <td>-0.619241</td>\n",
       "      <td>-2.243711</td>\n",
       "      <td>-0.271429</td>\n",
       "      <td>2.007845</td>\n",
       "      <td>1.213534</td>\n",
       "      <td>0.282344</td>\n",
       "      <td>0.579121</td>\n",
       "      <td>0.067367</td>\n",
       "      <td>0.241708</td>\n",
       "      <td>0.682524</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>-0.546859</td>\n",
       "      <td>-0.123055</td>\n",
       "      <td>-0.084889</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>-0.021944</td>\n",
       "      <td>29.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219130</td>\n",
       "      <td>120580.0</td>\n",
       "      <td>1.743525</td>\n",
       "      <td>-1.681429</td>\n",
       "      <td>-0.547387</td>\n",
       "      <td>-1.061113</td>\n",
       "      <td>-0.695825</td>\n",
       "      <td>2.458824</td>\n",
       "      <td>-1.632859</td>\n",
       "      <td>1.073529</td>\n",
       "      <td>1.068183</td>\n",
       "      <td>0.483337</td>\n",
       "      <td>0.274519</td>\n",
       "      <td>-0.346514</td>\n",
       "      <td>-0.409519</td>\n",
       "      <td>-0.564673</td>\n",
       "      <td>-0.143855</td>\n",
       "      <td>1.334855</td>\n",
       "      <td>0.160901</td>\n",
       "      <td>-0.087356</td>\n",
       "      <td>-0.066264</td>\n",
       "      <td>0.441788</td>\n",
       "      <td>0.543278</td>\n",
       "      <td>1.294571</td>\n",
       "      <td>0.309541</td>\n",
       "      <td>3.703925</td>\n",
       "      <td>-0.242579</td>\n",
       "      <td>0.068708</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.064690</td>\n",
       "      <td>163.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219131</td>\n",
       "      <td>120580.0</td>\n",
       "      <td>2.205568</td>\n",
       "      <td>-1.571445</td>\n",
       "      <td>-0.238965</td>\n",
       "      <td>-1.662517</td>\n",
       "      <td>-1.652324</td>\n",
       "      <td>-0.054701</td>\n",
       "      <td>-1.682064</td>\n",
       "      <td>0.105613</td>\n",
       "      <td>-1.177858</td>\n",
       "      <td>1.626352</td>\n",
       "      <td>0.601148</td>\n",
       "      <td>-0.041610</td>\n",
       "      <td>0.432748</td>\n",
       "      <td>-0.527684</td>\n",
       "      <td>-0.543665</td>\n",
       "      <td>0.043896</td>\n",
       "      <td>0.058472</td>\n",
       "      <td>0.622667</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>-0.366906</td>\n",
       "      <td>-0.131527</td>\n",
       "      <td>0.086623</td>\n",
       "      <td>0.291375</td>\n",
       "      <td>0.739087</td>\n",
       "      <td>-0.543006</td>\n",
       "      <td>-0.297813</td>\n",
       "      <td>0.043699</td>\n",
       "      <td>-0.037855</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>219132</td>\n",
       "      <td>120580.0</td>\n",
       "      <td>1.989728</td>\n",
       "      <td>-0.972909</td>\n",
       "      <td>-1.938259</td>\n",
       "      <td>-1.440129</td>\n",
       "      <td>-0.166855</td>\n",
       "      <td>-0.794048</td>\n",
       "      <td>0.252889</td>\n",
       "      <td>-0.399789</td>\n",
       "      <td>2.079398</td>\n",
       "      <td>-1.225592</td>\n",
       "      <td>-0.869368</td>\n",
       "      <td>1.647638</td>\n",
       "      <td>1.138026</td>\n",
       "      <td>-0.258468</td>\n",
       "      <td>-0.361765</td>\n",
       "      <td>-1.253326</td>\n",
       "      <td>0.099479</td>\n",
       "      <td>-0.587702</td>\n",
       "      <td>1.207085</td>\n",
       "      <td>-0.049136</td>\n",
       "      <td>-0.080115</td>\n",
       "      <td>-0.010732</td>\n",
       "      <td>-0.038550</td>\n",
       "      <td>0.656830</td>\n",
       "      <td>0.343470</td>\n",
       "      <td>-0.627529</td>\n",
       "      <td>-0.024338</td>\n",
       "      <td>-0.036143</td>\n",
       "      <td>120.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219133</td>\n",
       "      <td>120580.0</td>\n",
       "      <td>-1.943548</td>\n",
       "      <td>-1.668761</td>\n",
       "      <td>0.363601</td>\n",
       "      <td>-0.977610</td>\n",
       "      <td>2.684779</td>\n",
       "      <td>-2.037681</td>\n",
       "      <td>0.039709</td>\n",
       "      <td>-0.048895</td>\n",
       "      <td>-0.281749</td>\n",
       "      <td>-0.341879</td>\n",
       "      <td>0.471628</td>\n",
       "      <td>0.637604</td>\n",
       "      <td>-0.592416</td>\n",
       "      <td>0.331702</td>\n",
       "      <td>-1.451799</td>\n",
       "      <td>0.096467</td>\n",
       "      <td>-0.853439</td>\n",
       "      <td>-0.462060</td>\n",
       "      <td>-0.267098</td>\n",
       "      <td>0.391627</td>\n",
       "      <td>0.083389</td>\n",
       "      <td>-0.306918</td>\n",
       "      <td>0.247822</td>\n",
       "      <td>-0.391799</td>\n",
       "      <td>-0.790716</td>\n",
       "      <td>-0.025706</td>\n",
       "      <td>0.330758</td>\n",
       "      <td>0.335537</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146082</th>\n",
       "      <td>365211</td>\n",
       "      <td>172789.0</td>\n",
       "      <td>-0.661834</td>\n",
       "      <td>-0.622980</td>\n",
       "      <td>0.735580</td>\n",
       "      <td>-0.554067</td>\n",
       "      <td>0.869889</td>\n",
       "      <td>-0.389502</td>\n",
       "      <td>0.161226</td>\n",
       "      <td>0.069945</td>\n",
       "      <td>0.698829</td>\n",
       "      <td>-0.658935</td>\n",
       "      <td>-2.129855</td>\n",
       "      <td>-0.655069</td>\n",
       "      <td>-0.551589</td>\n",
       "      <td>-0.143536</td>\n",
       "      <td>-0.329767</td>\n",
       "      <td>0.625951</td>\n",
       "      <td>-0.949933</td>\n",
       "      <td>0.164734</td>\n",
       "      <td>0.079083</td>\n",
       "      <td>0.262408</td>\n",
       "      <td>-0.046068</td>\n",
       "      <td>-0.425692</td>\n",
       "      <td>0.253833</td>\n",
       "      <td>-1.076331</td>\n",
       "      <td>-0.999877</td>\n",
       "      <td>0.161938</td>\n",
       "      <td>0.149243</td>\n",
       "      <td>0.279708</td>\n",
       "      <td>94.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146083</th>\n",
       "      <td>365212</td>\n",
       "      <td>172789.0</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>0.340012</td>\n",
       "      <td>-0.589546</td>\n",
       "      <td>0.717091</td>\n",
       "      <td>-0.262765</td>\n",
       "      <td>0.726272</td>\n",
       "      <td>-0.070608</td>\n",
       "      <td>0.095958</td>\n",
       "      <td>-0.776078</td>\n",
       "      <td>-1.130049</td>\n",
       "      <td>0.506635</td>\n",
       "      <td>1.239831</td>\n",
       "      <td>-0.039782</td>\n",
       "      <td>0.446481</td>\n",
       "      <td>-0.049086</td>\n",
       "      <td>-0.746027</td>\n",
       "      <td>0.361708</td>\n",
       "      <td>-0.191256</td>\n",
       "      <td>0.064640</td>\n",
       "      <td>0.441215</td>\n",
       "      <td>1.284819</td>\n",
       "      <td>-0.141790</td>\n",
       "      <td>0.646930</td>\n",
       "      <td>-0.419964</td>\n",
       "      <td>-0.561426</td>\n",
       "      <td>0.326700</td>\n",
       "      <td>0.255166</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146084</th>\n",
       "      <td>365213</td>\n",
       "      <td>172789.0</td>\n",
       "      <td>-1.487918</td>\n",
       "      <td>1.769142</td>\n",
       "      <td>0.551671</td>\n",
       "      <td>0.361566</td>\n",
       "      <td>0.056347</td>\n",
       "      <td>0.084844</td>\n",
       "      <td>0.567545</td>\n",
       "      <td>-0.059899</td>\n",
       "      <td>0.331706</td>\n",
       "      <td>1.623577</td>\n",
       "      <td>0.807877</td>\n",
       "      <td>1.021134</td>\n",
       "      <td>1.069455</td>\n",
       "      <td>-0.322923</td>\n",
       "      <td>0.063989</td>\n",
       "      <td>-0.089844</td>\n",
       "      <td>-0.764603</td>\n",
       "      <td>0.739254</td>\n",
       "      <td>0.291846</td>\n",
       "      <td>0.792736</td>\n",
       "      <td>0.163500</td>\n",
       "      <td>1.287079</td>\n",
       "      <td>-0.186955</td>\n",
       "      <td>-0.349847</td>\n",
       "      <td>-0.161724</td>\n",
       "      <td>-0.213933</td>\n",
       "      <td>0.392745</td>\n",
       "      <td>0.070938</td>\n",
       "      <td>29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146085</th>\n",
       "      <td>365214</td>\n",
       "      <td>172790.0</td>\n",
       "      <td>-1.889979</td>\n",
       "      <td>-0.154869</td>\n",
       "      <td>0.068496</td>\n",
       "      <td>-1.906964</td>\n",
       "      <td>-1.743181</td>\n",
       "      <td>0.717490</td>\n",
       "      <td>0.981608</td>\n",
       "      <td>-0.209713</td>\n",
       "      <td>-0.556087</td>\n",
       "      <td>-0.283025</td>\n",
       "      <td>-1.664145</td>\n",
       "      <td>-0.559516</td>\n",
       "      <td>1.238936</td>\n",
       "      <td>-0.887569</td>\n",
       "      <td>-1.155718</td>\n",
       "      <td>1.379725</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>-1.190413</td>\n",
       "      <td>0.664771</td>\n",
       "      <td>-0.513829</td>\n",
       "      <td>0.121457</td>\n",
       "      <td>0.764642</td>\n",
       "      <td>-0.217844</td>\n",
       "      <td>0.104599</td>\n",
       "      <td>-0.008906</td>\n",
       "      <td>-0.204957</td>\n",
       "      <td>-0.752326</td>\n",
       "      <td>-0.155728</td>\n",
       "      <td>314.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146086</th>\n",
       "      <td>365215</td>\n",
       "      <td>172790.0</td>\n",
       "      <td>2.058491</td>\n",
       "      <td>-1.472979</td>\n",
       "      <td>-1.948388</td>\n",
       "      <td>-1.895306</td>\n",
       "      <td>1.160925</td>\n",
       "      <td>3.611489</td>\n",
       "      <td>-1.567759</td>\n",
       "      <td>0.813258</td>\n",
       "      <td>-0.046923</td>\n",
       "      <td>0.745883</td>\n",
       "      <td>0.014464</td>\n",
       "      <td>-0.580078</td>\n",
       "      <td>0.084964</td>\n",
       "      <td>-0.319678</td>\n",
       "      <td>0.902602</td>\n",
       "      <td>1.312460</td>\n",
       "      <td>-0.149362</td>\n",
       "      <td>-0.988297</td>\n",
       "      <td>0.309858</td>\n",
       "      <td>0.178640</td>\n",
       "      <td>0.351114</td>\n",
       "      <td>0.835645</td>\n",
       "      <td>0.128687</td>\n",
       "      <td>0.743448</td>\n",
       "      <td>-0.145395</td>\n",
       "      <td>-0.065332</td>\n",
       "      <td>0.023910</td>\n",
       "      <td>-0.045230</td>\n",
       "      <td>69.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146087 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      Time        V1        V2        V3        V4        V5   \n",
       "0       219129  120580.0  2.115519 -0.691809 -1.305514 -0.685655 -0.641265  \\\n",
       "1       219130  120580.0  1.743525 -1.681429 -0.547387 -1.061113 -0.695825   \n",
       "2       219131  120580.0  2.205568 -1.571445 -0.238965 -1.662517 -1.652324   \n",
       "3       219132  120580.0  1.989728 -0.972909 -1.938259 -1.440129 -0.166855   \n",
       "4       219133  120580.0 -1.943548 -1.668761  0.363601 -0.977610  2.684779   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "146082  365211  172789.0 -0.661834 -0.622980  0.735580 -0.554067  0.869889   \n",
       "146083  365212  172789.0 -0.098889  0.761900  0.340012 -0.589546  0.717091   \n",
       "146084  365213  172789.0 -1.487918  1.769142  0.551671  0.361566  0.056347   \n",
       "146085  365214  172790.0 -1.889979 -0.154869  0.068496 -1.906964 -1.743181   \n",
       "146086  365215  172790.0  2.058491 -1.472979 -1.948388 -1.895306  1.160925   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12   \n",
       "0      -0.764784 -0.924262 -0.023030 -0.230126  0.220610  1.058325 -0.723363  \\\n",
       "1       2.458824 -1.632859  1.073529  1.068183  0.483337  0.274519 -0.346514   \n",
       "2      -0.054701 -1.682064  0.105613 -1.177858  1.626352  0.601148 -0.041610   \n",
       "3      -0.794048  0.252889 -0.399789  2.079398 -1.225592 -0.869368  1.647638   \n",
       "4      -2.037681  0.039709 -0.048895 -0.281749 -0.341879  0.471628  0.637604   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "146082 -0.389502  0.161226  0.069945  0.698829 -0.658935 -2.129855 -0.655069   \n",
       "146083 -0.262765  0.726272 -0.070608  0.095958 -0.776078 -1.130049  0.506635   \n",
       "146084  0.084844  0.567545 -0.059899  0.331706  1.623577  0.807877  1.021134   \n",
       "146085  0.717490  0.981608 -0.209713 -0.556087 -0.283025 -1.664145 -0.559516   \n",
       "146086  3.611489 -1.567759  0.813258 -0.046923  0.745883  0.014464 -0.580078   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19   \n",
       "0      -0.619241 -2.243711 -0.271429  2.007845  1.213534  0.282344  0.579121  \\\n",
       "1      -0.409519 -0.564673 -0.143855  1.334855  0.160901 -0.087356 -0.066264   \n",
       "2       0.432748 -0.527684 -0.543665  0.043896  0.058472  0.622667  0.010671   \n",
       "3       1.138026 -0.258468 -0.361765 -1.253326  0.099479 -0.587702  1.207085   \n",
       "4      -0.592416  0.331702 -1.451799  0.096467 -0.853439 -0.462060 -0.267098   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "146082 -0.551589 -0.143536 -0.329767  0.625951 -0.949933  0.164734  0.079083   \n",
       "146083  1.239831 -0.039782  0.446481 -0.049086 -0.746027  0.361708 -0.191256   \n",
       "146084  1.069455 -0.322923  0.063989 -0.089844 -0.764603  0.739254  0.291846   \n",
       "146085  1.238936 -0.887569 -1.155718  1.379725  0.114537 -1.190413  0.664771   \n",
       "146086  0.084964 -0.319678  0.902602  1.312460 -0.149362 -0.988297  0.309858   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26   \n",
       "0       0.067367  0.241708  0.682524  0.037769 -0.546859 -0.123055 -0.084889  \\\n",
       "1       0.441788  0.543278  1.294571  0.309541  3.703925 -0.242579  0.068708   \n",
       "2      -0.366906 -0.131527  0.086623  0.291375  0.739087 -0.543006 -0.297813   \n",
       "3      -0.049136 -0.080115 -0.010732 -0.038550  0.656830  0.343470 -0.627529   \n",
       "4       0.391627  0.083389 -0.306918  0.247822 -0.391799 -0.790716 -0.025706   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "146082  0.262408 -0.046068 -0.425692  0.253833 -1.076331 -0.999877  0.161938   \n",
       "146083  0.064640  0.441215  1.284819 -0.141790  0.646930 -0.419964 -0.561426   \n",
       "146084  0.792736  0.163500  1.287079 -0.186955 -0.349847 -0.161724 -0.213933   \n",
       "146085 -0.513829  0.121457  0.764642 -0.217844  0.104599 -0.008906 -0.204957   \n",
       "146086  0.178640  0.351114  0.835645  0.128687  0.743448 -0.145395 -0.065332   \n",
       "\n",
       "             V27       V28  Amount  \n",
       "0       0.004720 -0.021944   29.95  \n",
       "1       0.002629  0.064690  163.50  \n",
       "2       0.043699 -0.037855   16.00  \n",
       "3      -0.024338 -0.036143  120.98  \n",
       "4       0.330758  0.335537    1.98  \n",
       "...          ...       ...     ...  \n",
       "146082  0.149243  0.279708   94.81  \n",
       "146083  0.326700  0.255166   24.99  \n",
       "146084  0.392745  0.070938   29.99  \n",
       "146085 -0.752326 -0.155728  314.00  \n",
       "146086  0.023910 -0.045230   69.00  \n",
       "\n",
       "[146087 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in training data\n",
    "train = pd.read_csv(\"/cs/studres/ID5059/Coursework/Coursework-2/data/train.csv\")\n",
    "\n",
    "# read in test data\n",
    "test = pd.read_csv(\"/cs/studres/ID5059/Coursework/Coursework-2/data/test.csv\")\n",
    "\n",
    "# Clear the maximum number of columns to be displayed, so that all will be visible.\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "display(train)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada5fdfb",
   "metadata": {},
   "source": [
    "# Original Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0cc9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set id as index\n",
    "train = train.set_index('id')\n",
    "test = test.set_index('id')\n",
    "\n",
    "# split train set into X_train, y_train\n",
    "y_train = train['Class']\n",
    "X_train = train.drop('Class', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ef2f6",
   "metadata": {},
   "source": [
    "# SMOTE Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b6ec29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c04e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_train_SMOTE, y_train_SMOTE = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# apply random undersampling to balance the class distribution\n",
    "rus = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_SMOTE, y_train_SMOTE = rus.fit_resample(X_train_SMOTE, y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef831bc",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f664189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m { \n\u001b[0;32m      3\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m:        [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m      4\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m75\u001b[39m, \u001b[38;5;241m100\u001b[39m] \n\u001b[0;32m      5\u001b[0m          }\n\u001b[0;32m      7\u001b[0m tree_train \u001b[38;5;241m=\u001b[39m GridSearchCV(tree\u001b[38;5;241m.\u001b[39mDecisionTreeClassifier(), params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m tree_train \u001b[38;5;241m=\u001b[39m \u001b[43mclf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m tree_train\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit to original train with CV for parameter selection\n",
    "# params = { \n",
    "#           'criterion':        ['gini', 'entropy', 'log_loss'], \n",
    "#          'min_samples_leaf': [75, 100] \n",
    "#         }\n",
    "\n",
    "#tree_train = GridSearchCV(tree.DecisionTreeClassifier(), params, cv=2)\n",
    "#tree_train = clf_train.fit(X_train, y_train)\n",
    "#tree_train.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to SMOTE train with CV for parameter selection\n",
    "#params = { \n",
    "#          'criterion':        ['gini', 'entropy', 'log_loss'], \n",
    "#           'min_samples_leaf': [75, 100] \n",
    "#         }\n",
    "\n",
    "#tree_SMOTE = GridSearchCV(tree.DecisionTreeClassifier(), params, cv=2)\n",
    "#tree_SMOTE = clf_SMOTE.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "#tree_SMOTE.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d213e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tree object\n",
    "tree1 = DecisionTreeClassifier(criterion = 'gini', min_samples_leaf = 100)\n",
    "# train tree on original training data\n",
    "tree_train = tree1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2b83a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tree object\n",
    "tree2 = DecisionTreeClassifier(criterion = 'gini', min_samples_leaf = 100)\n",
    "# train tree on original training data\n",
    "tree_SMOTE = tree2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610662d",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0161484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do k folds cross validation\n",
    "num_folds = 5\n",
    "\n",
    "# create stratfied k-fold object\n",
    "strat_kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa72cd95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# do stratfied cv on train set \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tree_train_cv \u001b[38;5;241m=\u001b[39m cross_val_score(\u001b[43mtree_train\u001b[49m, X_train, y_train, cv\u001b[38;5;241m=\u001b[39mstrat_kfold, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tree_train' is not defined"
     ]
    }
   ],
   "source": [
    "# do stratfied cv on train set \n",
    "tree_train_cv = cross_val_score(tree_train, X_train, y_train, cv=strat_kfold, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bb5e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do stratified cv on SMOTE set \n",
    "tree_SMOTE_cv = cross_val_score(tree_SMOTE, X_train_SMOTE, y_train_SMOTE, cv=strat_kfold, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35aaff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67052682 0.6734344  0.64764421 0.61825765 0.6641468 ]\n",
      "[0.98139506 0.97990637 0.98046229 0.98046783 0.98046803]\n"
     ]
    }
   ],
   "source": [
    "# compare cv scores\n",
    "tree_meanCV = tree_train_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc4252ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal here. Maybe you meant '==' instead of '='? (2395860588.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[35], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    tree_train_cv_comp = pd.DataFrame['Original' = tree_meanCV, 'Imputed' = tree_meanCV_imputed]\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to literal here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "tree_train_cv_comp = pd.DataFrame[{'Original' = tree_meanCV, 'Imputed' = tree_meanCV_imputed}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339596d",
   "metadata": {},
   "source": [
    "# Fit to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c0f3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit trained tree\n",
    "predicted_tree_train = tree_train.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43d3ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit SMOTE trained tree\n",
    "predicted_tree_SMOTE = tree_SMOTE.predict_proba(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7cf019",
   "metadata": {},
   "source": [
    "## Export for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615f4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function to format results\n",
    "\n",
    "def output_func(predictions):\n",
    "    results = pd.DataFrame({'id': test.index, 'Class': predictions[:,1]})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "203009c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_train_kaggle = output_func(predicted_tree_train)\n",
    "tree_SMOTE_kaggle = output_func(predicted_tree_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0aef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make function to export csv\n",
    "\n",
    "def export_func (results, filename = 'out'):\n",
    "    results.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d4aa92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csvs\n",
    "export_func(tree_train_kaggle, 'tree_train_kaggle.csv')\n",
    "export_func(tree_SMOTE_kaggle, 'tree_SMOTE_kaggle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b0faa",
   "metadata": {},
   "source": [
    "train kaggle score: 0.68799\n",
    "SMOTE kaggle score: 0.67115"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc415",
   "metadata": {},
   "source": [
    "# Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b987424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logisitic regression requires centered and scaled data\n",
    "\n",
    "#create scaler objects for both types of data\n",
    "scaler_train = StandardScaler()\n",
    "scaler_SMOTE = StandardScaler()\n",
    "\n",
    "# scale the training data\n",
    "X_train_scaled = scaler_train.fit_transform(X_train)\n",
    "X_SMOTE_scaled = scaler_SMOTE.fit_transform(X_train_SMOTE)\n",
    "\n",
    "#scale the test data\n",
    "X_test_scaled = scaler_train.transform(test)\n",
    "X_test_SMOTE_scaled = scaler_SMOTE.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c82319a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat logisitic regression onject\n",
    "logi_mod1 = LogisticRegression(random_state=42)\n",
    "logi_mod2 = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2193d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to both train and SMOTE\n",
    "logi_train = logi_mod2.fit(X_train_scaled, y_train)\n",
    "logi_SMOTE = logi_mod2.fit(X_SMOTE_scaled, y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf89d4",
   "metadata": {},
   "source": [
    "# Logisitc Regression using Eleastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e459dbab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Perform cross-validation grid search\u001b[39;00m\n\u001b[0;32m      8\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(logi_elastic, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Choose the best hyperparameters\u001b[39;00m\n\u001b[0;32m     12\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1289\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1291\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[0;32m   1292\u001b[0m     path_func(\n\u001b[0;32m   1293\u001b[0m         X,\n\u001b[0;32m   1294\u001b[0m         y,\n\u001b[0;32m   1295\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[0;32m   1296\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1297\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1298\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1299\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1300\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1301\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1302\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[0;32m   1303\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1304\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m   1305\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1306\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1307\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1308\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[0;32m   1309\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1310\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1311\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[0;32m   1312\u001b[0m     )\n\u001b[0;32m   1313\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[0;32m   1314\u001b[0m )\n\u001b[0;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:524\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    521\u001b[0m         alpha \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m l1_ratio)\n\u001b[0;32m    522\u001b[0m         beta \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m l1_ratio\n\u001b[1;32m--> 524\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[39m=\u001b[39m sag_solver(\n\u001b[0;32m    525\u001b[0m         X,\n\u001b[0;32m    526\u001b[0m         target,\n\u001b[0;32m    527\u001b[0m         sample_weight,\n\u001b[0;32m    528\u001b[0m         loss,\n\u001b[0;32m    529\u001b[0m         alpha,\n\u001b[0;32m    530\u001b[0m         beta,\n\u001b[0;32m    531\u001b[0m         max_iter,\n\u001b[0;32m    532\u001b[0m         tol,\n\u001b[0;32m    533\u001b[0m         verbose,\n\u001b[0;32m    534\u001b[0m         random_state,\n\u001b[0;32m    535\u001b[0m         \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    536\u001b[0m         max_squared_sum,\n\u001b[0;32m    537\u001b[0m         warm_start_sag,\n\u001b[0;32m    538\u001b[0m         is_saga\u001b[39m=\u001b[39;49m(solver \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    539\u001b[0m     )\n\u001b[0;32m    541\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    543\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msolver must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m solver\n\u001b[0;32m    545\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ffinl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:325\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent sag implementation does not handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    324\u001b[0m sag \u001b[39m=\u001b[39m sag64 \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64 \u001b[39melse\u001b[39;00m sag32\n\u001b[1;32m--> 325\u001b[0m num_seen, n_iter_ \u001b[39m=\u001b[39m sag(\n\u001b[0;32m    326\u001b[0m     dataset,\n\u001b[0;32m    327\u001b[0m     coef_init,\n\u001b[0;32m    328\u001b[0m     intercept_init,\n\u001b[0;32m    329\u001b[0m     n_samples,\n\u001b[0;32m    330\u001b[0m     n_features,\n\u001b[0;32m    331\u001b[0m     n_classes,\n\u001b[0;32m    332\u001b[0m     tol,\n\u001b[0;32m    333\u001b[0m     max_iter,\n\u001b[0;32m    334\u001b[0m     loss,\n\u001b[0;32m    335\u001b[0m     step_size,\n\u001b[0;32m    336\u001b[0m     alpha_scaled,\n\u001b[0;32m    337\u001b[0m     beta_scaled,\n\u001b[0;32m    338\u001b[0m     sum_gradient_init,\n\u001b[0;32m    339\u001b[0m     gradient_memory_init,\n\u001b[0;32m    340\u001b[0m     seen_init,\n\u001b[0;32m    341\u001b[0m     num_seen_init,\n\u001b[0;32m    342\u001b[0m     fit_intercept,\n\u001b[0;32m    343\u001b[0m     intercept_sum_gradient,\n\u001b[0;32m    344\u001b[0m     intercept_decay,\n\u001b[0;32m    345\u001b[0m     is_saga,\n\u001b[0;32m    346\u001b[0m     verbose,\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    349\u001b[0m \u001b[39mif\u001b[39;00m n_iter_ \u001b[39m==\u001b[39m max_iter:\n\u001b[0;32m    350\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    351\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    352\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    353\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set a parameter grid\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {'l1_ratio': [0.5, 0.9]}\n",
    "# define logisitc regressor with elastic net\n",
    "logi_elastic = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=1000)\n",
    "\n",
    "# Perform cross-validation grid search\n",
    "grid_search = GridSearchCV(logi_elastic, param_grid, cv=4)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Choose the best hyperparameters\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model\n",
    "logi_elastic_train = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000, **best_params)\n",
    "logi_elastic_train.fit(X_train_ y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5479dba2",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "976cf41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do stratified k fold on original train\n",
    "logi_train_cv = cross_val_score(logi_train, X_train_scaled, y_train, cv = strat_kfold, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75ecc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do on smote data\n",
    "logi_SMOTE_cv = cross_val_score(logi_SMOTE, X_SMOTE_scaled, y_train_SMOTE, cv = strat_kfold, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84d58f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8675839649162649"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi_train_meanCV = logi_train_cv.mean()\n",
    "logi_SMOTE_meanCV = logi_SMOTE_cv.mean()\n",
    "\n",
    "logi_train_meanCV\n",
    "logi_SMOTE_meanCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make object for table\n",
    "logi_train_cv_comp = pd.DataFrame['Original' = logi_train_meanCV, 'Imputed' = logi_train_imputed_meanCV]\n",
    "logi_SMOTE_cv_comp = pd.DataFrame['Original' = logi_SMOTE_meanCV, 'Imputed' = logi_SMOTE_imputed_meanCV]\n",
    "logi_elastic_cv_comp = pd.DataFrame['Original' = logi_elastic_meanCV, 'Imputed' = logi_elastic_imputed_meanCV]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abb5186",
   "metadata": {},
   "source": [
    "# Fit to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfbc72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test for both models\n",
    "predicted_logi_train = logi_train.predict_proba(X_test_scaled)\n",
    "predicted_logi_SMOTE = logi_SMOTE.predict_proba(X_test_SMOTE_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3df0cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create results array\n",
    "logi_train_kaggle = output_func(predicted_logi_train)\n",
    "logi_SMOTE_kaggle = output_func(predicted_logi_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1bc8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csvs\n",
    "export_func(logi_train_kaggle, 'logi_train_kaggle.csv')\n",
    "export_func(logi_SMOTE_kaggle, 'logi_SMOTE_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06619b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle scores\n",
    "logi_train = 0.79312\n",
    "logi_SMOTE = 0.81797\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282de6e",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f27139b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Random Forrest Classifier with optimum paramters of the decision tree\n",
    "rfc = RandomForestClassifier(n_estimators = 10, max_depth= 25, min_samples_leaf= 100, criterion= 'gini')\n",
    "\n",
    "rfc_train = rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d6b8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do k folds cross validation\n",
    "num_folds = 5\n",
    "\n",
    "# create stratfied k-fold object\n",
    "strat_kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "\n",
    "# do stratified k fold on original train\n",
    "rfc_train_cv = cross_val_score(rfc_train, X_train, y_train, cv = strat_kfold, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e420c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do k folds cross validation on imputed data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcd98040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808581262511078"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_meanCV = rfc_train_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make object for table\n",
    "rfc_cv_comp = pd.DataFrame['Original' = rfc_meanCV, 'Imputed' = rfc_meanCV_imputed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaa0cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predictions = rfc_train.predict_proba(test)\n",
    "rfc_results = output_func(predictions= rfc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "015544a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_func(rfc_results, filename= 'rfc_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baa3b15",
   "metadata": {},
   "source": [
    "# ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85b4360e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1,\n",
       "                                                    random_state=618),\n",
       "                   learning_rate=0.1, n_estimators=250, random_state=618)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1,\n",
       "                                                    random_state=618),\n",
       "                   learning_rate=0.1, n_estimators=250, random_state=618)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=1, random_state=618)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=1, random_state=618)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1,\n",
       "                                                    random_state=618),\n",
       "                   learning_rate=0.1, n_estimators=250, random_state=618)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_simple = DecisionTreeClassifier(max_depth = 1, random_state = SEED);\n",
    "decision_tree_simple.fit(X_train, y_train)\n",
    "\n",
    "ada_final = AdaBoostClassifier(decision_tree_simple, n_estimators = 250, algorithm = \"SAMME.R\", learning_rate = 0.1, random_state = SEED);\n",
    "ada_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform cross validation original\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "# create stratfied k-fold object\n",
    "strat_kfold = StratifiedKFold(n_splits = num_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "# do stratified k fold on original train\n",
    "ada_cv = cross_val_score(ada_final, X_train, y_train, cv = strat_kfold, scoring='roc_auc')\n",
    "\n",
    "ada_meanCV = ada_cv.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf8a22",
   "metadata": {},
   "source": [
    "# perform cross validation on the imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make object for table\n",
    "ada_cv_comp = pd.DataFrame['Original' = ada_meanCV, 'Imputed' = ada_meanCV_imputed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f62184",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227cc57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to test data and export for kaggle\n",
    "ada_predictions = ada_final.predict_proba(test)\n",
    "\n",
    "ada_results = output_func(ada_predictions)\n",
    "\n",
    "export_func(ada_results, 'ada_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58aa726",
   "metadata": {},
   "source": [
    "# Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03feb4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>Original</th>\n",
       "      <th>Imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         level_0  level_1  Original  Imputed\n",
       "0  Random Forest        0      0.85     0.84\n",
       "1       AdaBoost        0      0.81     0.79"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the first data frame\n",
    "rfc_meanCV = [0.85]\n",
    "rfc_meanCV_imputed = [0.84]\n",
    "rfc_cv_comp = pd.DataFrame({'Original': rfc_meanCV, 'Imputed': rfc_meanCV_imputed})\n",
    "\n",
    "# Create the second data frame\n",
    "ada_meanCV = [0.81]\n",
    "ada_meanCV_imputed = [0.79]\n",
    "ada_cv_comp = pd.DataFrame({'Original': ada_meanCV, 'Imputed': ada_meanCV_imputed})\n",
    "\n",
    "# Create a dictionary with the data frames and their names\n",
    "dfs = {'tree'Random Forest': rfc_cv_comp, 'AdaBoost': ada_cv_comp}\n",
    "\n",
    "# Concatenate the data frames and add the names as column labels\n",
    "result = pd.concat([rfc_cv_comp, ada_cv_comp], axis = 0, keys=dfs.keys()).reset_index()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96f56ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Random Forest AdaBoost\n",
      "                     0        0\n",
      "Original          0.85     0.81\n",
      "Imputed           0.84     0.79\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with the data frames and their names\n",
    "dfs = {'Decision Tree': tree_train_cv_comp, 'Logistic Regression': logi_train_cv_comp, \n",
    "'SMOTE Logistic Regression': logi_SMOTE_cv_comp, 'Elastic Net Logistic Regression': logi_elastic_cv_comp,\n",
    " 'Random Forest': rfc_cv_comp, 'AdaBoost': ada_cv_comp}\n",
    "\n",
    "# Concatenate the data frames along the row axis\n",
    "result = pd.concat(dfs.values(), axis=0, keys=dfs.keys())\n",
    "\n",
    "# Print the resulting data frame\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6dd48ac52229d09d75c4e02347319d04260892922f8903865b49a468f73fb301"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
